{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 02 - Building the vector database",
   "id": "30600691bf5c8d28"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Notebook steps:\n",
    "\n",
    "- Load TSV that contains the chunks to index\n",
    "- Generate vector indexing configurations from `config.yml`\n",
    "- Index the chunks in the vector database using the `VectorDB` abstraction\n",
    "\n",
    "\n",
    "When the chunks are encoded by the embedding model, they are stored in a vector database. When a user enters a query, it is also encoded by the same model, and then compared to the vectors in the database to identify the most similar documents.\n",
    "\n",
    "The main technical challenge is as follows:\n",
    "> Given a query vector, quickly find its **k nearest neighbors** in the vector database, i.e., the k most relevant documents.\n",
    "\n",
    "\n",
    "Let's start by create the vector database and save it to disk.\n",
    "\n"
   ],
   "id": "7258a0e8f82e5852"
  },
  {
   "cell_type": "code",
   "id": "4d7515da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T17:25:27.025646Z",
     "start_time": "2025-07-08T17:25:20.773989Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "\n",
    "from lib.io_utils import read_yaml\n",
    "from lib.vector_store import VectorDB\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "9f2c7612",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T17:25:27.041038Z",
     "start_time": "2025-07-08T17:25:27.035446Z"
    }
   },
   "source": [
    "## configuration loading\n",
    "config = read_yaml(\"../config.yml\")\n",
    "data_path = \"../data/raw/encpos_chunked_tok_512_51.csv\"\n",
    "defaults = config.get(\"defaults\", {})"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "44bceb3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T17:25:29.647430Z",
     "start_time": "2025-07-08T17:25:28.530484Z"
    }
   },
   "source": [
    "## data loading\n",
    "if not os.path.exists(data_path):\n",
    "    raise FileNotFoundError(f\"File Not Found: {data_path}. Run first the notebook: 01-prepare_chunk_corpus.ipynb.\")\n",
    "df = pd.read_csv(data_path, sep=\"\\t\")\n",
    "print(f\"Total chunks to index: {len(df)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de chunks à indexer : 39377\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We prepare the configurations to create our persistent vector databases.",
   "id": "ad2cc6d69892a920"
  },
  {
   "cell_type": "code",
   "id": "1a922b72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T17:25:32.013225Z",
     "start_time": "2025-07-08T17:25:32.006340Z"
    }
   },
   "source": [
    "vector_indexing = []\n",
    "for entry in config.get(\"vector_indexing\", []):\n",
    "    model_id = entry[\"model_id\"]\n",
    "    model = next((m for m in config[\"embedding_models\"] if m[\"id\"] == model_id), None)\n",
    "    if not model:\n",
    "        raise ValueError(f\"Modèle non trouvé : {model_id}\")\n",
    "\n",
    "    for backend in entry[\"backends\"]:\n",
    "        suffix = f\"{model_id}_{backend}\"\n",
    "        name = f\"{model['name']} - {backend.upper()}\"\n",
    "        collection_name = f\"{defaults.get('collection_prefix', 'encpos')}_{model_id}\"\n",
    "        path = os.path.join(defaults.get(\"base_path\", \"data/vectordb\"), suffix)\n",
    "\n",
    "        vector_indexing.append({\n",
    "            \"name\": name,\n",
    "            \"backend\": backend,\n",
    "            \"embedding_model\": model[\"model_path\"],\n",
    "            \"metric\": defaults.get(\"metric\", \"cosine\"),\n",
    "            \"text_column\": defaults.get(\"text_column\", \"full_chunk\"),\n",
    "            \"metadata_columns\": defaults.get(\"metadata_columns\", []),\n",
    "            \"path\": path,\n",
    "            \"qdrant_collection_name\": collection_name,\n",
    "            \"k\": defaults.get(\"k\", 10),\n",
    "            \"force_rebuild\": defaults.get(\"force_rebuild\", False)\n",
    "        })"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To efficiently index our data in a vector database that could have thousands of documents, we need to pick two key things:\n",
    "\n",
    "- A **distance metric** to compare vectors (like cosine similarity, Euclidean distance, etc.);\n",
    "\n",
    "- A **nearest neighbors search algorithm** to quickly find relevant documents.\n",
    "\n",
    "In the following cell, we have set up a main loop that builds a vector database for each configuration defined in the `config.yml` file.\n",
    "The goal is to test different combinations of embedding models and storage backends.\n",
    "\n",
    "The two backends currently supported are:\n",
    "\n",
    "- Faiss: very fast for indexing and searching, but metadata filters are limited;\n",
    "\n",
    "- LanceDB: slower for indexing, but allows complex queries on metadata, for example in SQL.\n",
    "\n",
    "We chose to use cosine similarity as the metric for comparing vectors. It measures the angle between two vectors, which allows their direction to be compared independently of their norm. This requires normalizing all vectors (i.e., giving them a unit norm) before indexing or searching.\n",
    "\n",
    "To facilitate indexing, we have developed a Python abstraction called `VectorDB` that supports:\n",
    "\n",
    "- Vector normalization\n",
    "\n",
    "- Creation of vector databases and their persistence\n",
    "\n",
    "- Indexing of embeddings\n",
    "\n",
    "- Searching\n",
    "\n",
    "This abstraction allows us to compare different models and backends in a uniform manner and evaluate them under fair conditions.\n",
    "\n"
   ],
   "id": "1b548879d9b99db8"
  },
  {
   "cell_type": "code",
   "id": "85445417",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T18:17:40.710798Z",
     "start_time": "2025-07-08T17:25:38.262535Z"
    }
   },
   "source": [
    "%%time\n",
    "#df = df.sample(n=50)\n",
    "for conf in vector_indexing:\n",
    "    print(\"\\n--- Indexation in progress ---\")\n",
    "    print(\"Nom:\", conf[\"name\"])\n",
    "\n",
    "    db = VectorDB(\n",
    "        backend=conf[\"backend\"],\n",
    "        embedding_model=conf[\"embedding_model\"],\n",
    "        metric=conf[\"metric\"],\n",
    "        path=conf[\"path\"],\n",
    "        k=conf[\"k\"],\n",
    "        force_rebuild=conf[\"force_rebuild\"]\n",
    "    )\n",
    "\n",
    "\n",
    "    db.add_from_dataframe(\n",
    "        df=df,\n",
    "        text_column=conf[\"text_column\"],\n",
    "        metadata_columns=conf[\"metadata_columns\"]\n",
    "    )\n",
    "\n",
    "    db.save()\n",
    "    print(\"📦 Index is created:\", conf[\"name\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Indexation en cours ---\n",
      "Nom: CamemBERT Large - LANCEDB\n",
      "📦 Initialisation de LanceDB à data/vectordb/camembert-large_lancedb\n",
      "🆕 Table LanceDB 'camembert-large_lancedb' à créer lors de l'indexation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Préparation des documents pour lancedb: 100%|██████████| 39377/39377 [00:01<00:00, 21462.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Création de la table LanceDB 'camembert-large_lancedb' à partir des documents...\n",
      "📦 Indexation terminée pour: CamemBERT Large - LANCEDB\n",
      "\n",
      "--- Indexation en cours ---\n",
      "Nom: CamemBERT Base - LANCEDB\n",
      "📦 Initialisation de LanceDB à data/vectordb/camembert-base_lancedb\n",
      "🆕 Table LanceDB 'camembert-base_lancedb' à créer lors de l'indexation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Préparation des documents pour lancedb: 100%|██████████| 39377/39377 [00:01<00:00, 37788.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Création de la table LanceDB 'camembert-base_lancedb' à partir des documents...\n",
      "📦 Indexation terminée pour: CamemBERT Base - LANCEDB\n",
      "\n",
      "--- Indexation en cours ---\n",
      "Nom: Multilingual DistilUSE - LANCEDB\n",
      "📦 Initialisation de LanceDB à data/vectordb/multilingual_lancedb\n",
      "🆕 Table LanceDB 'multilingual_lancedb' à créer lors de l'indexation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Préparation des documents pour lancedb: 100%|██████████| 39377/39377 [00:01<00:00, 36957.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Création de la table LanceDB 'multilingual_lancedb' à partir des documents...\n",
      "📦 Indexation terminée pour: Multilingual DistilUSE - LANCEDB\n",
      "CPU times: user 4min 24s, sys: 3min 8s, total: 7min 32s\n",
      "Wall time: 52min 2s\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "dee931056f69ba19"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "➡️ Notebook suivant : [03-assemble_rag.ipynb](./03-assemble_rag.ipynb)",
   "id": "6812a98481fd9b54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ef67d4eced927718"
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
